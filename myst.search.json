{"version":"1","records":[{"hierarchy":{"lvl1":"EOxHub Workspaces notebooks"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"EOxHub Workspaces notebooks"},"content":"A curated list of Jupyter notebooks demonstrating the capabilities of the\nEOxHub workspaces. These notebooks can be directly executed by\nEOxHub workspace customers within their own Jupyter Lab environment without\nfurther setup.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"eoAPI registration example"},"type":"lvl1","url":"/notebooks/eoapi/eoapi-registration","position":0},{"hierarchy":{"lvl1":"eoAPI registration example"},"content":"This notebook demonstrates how to register data on the workspace eoAPI instance. The main step is creation of STAC metadata information to pass it to the eoAPI STAC endpoint.\nIn order to show the full flow this notebooks also fetches some sample data and does following steps:\n\nDownload: Download file to mounted bucket path.\n\nCollection creation: Create the STAC collection the file will be registered to.\n\nMetadata extraction: Extract as much information as possible from source file to create STAC item.\n\nIngest: Post the resulting STAC ttem to the eoAPI STAC endpoint.\n\n","type":"content","url":"/notebooks/eoapi/eoapi-registration","position":1},{"hierarchy":{"lvl1":"eoAPI registration example","lvl3":"Environment Checks"},"type":"lvl3","url":"/notebooks/eoapi/eoapi-registration#environment-checks","position":2},{"hierarchy":{"lvl1":"eoAPI registration example","lvl3":"Environment Checks"},"content":"\n\n# First some checks to see the environment is as expected\nimport sys\nimport os\nimport importlib.util\n\n# List the packages to check\nrequired = [\"pystac\", \"rio_stac\", \"pystac_client\", \"requests\", \"rasterio\"]\nmissing = [p for p in required if importlib.util.find_spec(p.replace('-','_')) is None]\n\nif missing:\n    print(f\"❌ ERROR: Missing packages: {', '.join(missing)}\")\n    print(\"It looks like the wrong Conda kernel is active. Please switch kernels and try again.\")\n    sys.exit(\"Execution stopped: Missing dependencies.\")\n\n# If check passes, proceed with imports\nfrom datetime import datetime, timezone\nfrom pystac import Collection, Extent, SpatialExtent, TemporalExtent, Link\nfrom rio_stac import create_stac_item\nimport rasterio\nimport requests\n\nprint(\"✅ Environment ready.\")\n\n\n\n","type":"content","url":"/notebooks/eoapi/eoapi-registration#environment-checks","position":3},{"hierarchy":{"lvl1":"eoAPI registration example","lvl2":"Configuration"},"type":"lvl2","url":"/notebooks/eoapi/eoapi-registration#configuration","position":4},{"hierarchy":{"lvl1":"eoAPI registration example","lvl2":"Configuration"},"content":"If using your own file adjust FILE_PATH to match its location and remove the download step.\n\nSTAC_API_URL = \"http://eoapi-rw-stac:8080\" \nCOLLECTION_ID = \"demo-collection\"\nCOG_SOURCE_URL = \"https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/36/Q/WD/2020/7/S2A_36QWD_20200701_0_L2A/TCI.tif\"\nFILE_PATH = \"./bucket/demo_data/TCI.tif\"\n\nos.makedirs(os.path.dirname(FILE_PATH), exist_ok=True)\n\n\n\n","type":"content","url":"/notebooks/eoapi/eoapi-registration#configuration","position":5},{"hierarchy":{"lvl1":"eoAPI registration example","lvl2":"1. Download"},"type":"lvl2","url":"/notebooks/eoapi/eoapi-registration#id-1-download","position":6},{"hierarchy":{"lvl1":"eoAPI registration example","lvl2":"1. Download"},"content":"\n\n# First we download the example file and put it into the mounted bucket\n# You can also use the File Browser to upload your data\n# (should be used for files smaller then 1 GB)\nif os.path.exists(FILE_PATH):\n    print(f\"File exists at {FILE_PATH}. Skipping.\")\nelse:\n    print(f\"Downloading to {FILE_PATH}...\")\n    with requests.get(COG_SOURCE_URL, stream=True) as r:\n        r.raise_for_status()\n        with open(FILE_PATH, 'wb') as f:\n            for chunk in r.iter_content(chunk_size=8192):\n                f.write(chunk)\n\n\n\n","type":"content","url":"/notebooks/eoapi/eoapi-registration#id-1-download","position":7},{"hierarchy":{"lvl1":"eoAPI registration example","lvl2":"2. Collection creation"},"type":"lvl2","url":"/notebooks/eoapi/eoapi-registration#id-2-collection-creation","position":8},{"hierarchy":{"lvl1":"eoAPI registration example","lvl2":"2. Collection creation"},"content":"\n\n# Then we create the collection (only if it does not already exist)\ncheck_url = f\"{STAC_API_URL}/collections/{COLLECTION_ID}\"\nresp = requests.get(check_url)\nif resp.status_code == 200:\n    print(f\"Collection '{COLLECTION_ID}' exists.\")\nelse:\n    print(f\"Creating collection '{COLLECTION_ID}'...\")\n    coll = Collection(\n        id=COLLECTION_ID,\n        title=\"Demo collection\",\n        description=\"Demo COG collection\",\n        extent=Extent(SpatialExtent([[-180, -90, 180, 90]]), TemporalExtent([[datetime(2020,1,1,tzinfo=timezone.utc), None]])),\n        license=\"CC-BY-4.0\"\n    )\n    # Sending a POST request with the Collection json to create the collection\n    requests.post(f\"{STAC_API_URL}/collections\", json=coll.to_dict()).raise_for_status()\n\n\n\n# If we wanted to delete the collection we could use following command\nrequests.delete(f\"{STAC_API_URL}/collections/{COLLECTION_ID}\")\n\n\n\n","type":"content","url":"/notebooks/eoapi/eoapi-registration#id-2-collection-creation","position":9},{"hierarchy":{"lvl1":"eoAPI registration example","lvl2":"3. Metadata Extraction"},"type":"lvl2","url":"/notebooks/eoapi/eoapi-registration#id-3-metadata-extraction","position":10},{"hierarchy":{"lvl1":"eoAPI registration example","lvl2":"3. Metadata Extraction"},"content":"\n\n# We need a STAC item definition in order to register it into the collection\n# see https://github.com/radiantearth/stac-spec/blob/master/item-spec/item-spec.md for further details\n\n# rio-stac provides a useful helper tool create_stac_item\n# to extract metadata from the raster file and create a STAC item from it\n\n# We need to define the connected bucket to this workspace\nBUCKET = \"aducat\" #os.getenv(\"workspace_BUCKET\")\nROOT_FILE_PATH = FILE_PATH.replace(\"./bucket\", \"\")\n# cloud location eoAPI TiTiler will access the data assets from\nS3_URI = f\"s3://{BUCKET}{ROOT_FILE_PATH}\"\n\nitem = create_stac_item(\n    source=FILE_PATH,\n    asset_href=S3_URI,\n    id=os.path.basename(ROOT_FILE_PATH).split('.')[0],\n    collection=COLLECTION_ID,\n    asset_name=\"data\"\n)\n\n# Add preview link to allow rendering data in eoAPI GUI\neoapi_endpoint = os.getenv(\"workspace_RASTER_ENDPOINT\")\nxyz = f\"{eoapi_endpoint}/collections/{COLLECTION_ID}/items/{item.id}/tiles/WebMercatorQuad/{{z}}/{{x}}/{{y}}?assets=data\"\nitem.add_link(Link(rel=\"xyz\", target=xyz, media_type=\"application/json\"))\n\n\n\n\n# We can print the item by uncommenting if we want to have a look\n# item.to_dict()\n\n\n\n","type":"content","url":"/notebooks/eoapi/eoapi-registration#id-3-metadata-extraction","position":11},{"hierarchy":{"lvl1":"eoAPI registration example","lvl2":"4. Ingestion"},"type":"lvl2","url":"/notebooks/eoapi/eoapi-registration#id-4-ingestion","position":12},{"hierarchy":{"lvl1":"eoAPI registration example","lvl2":"4. Ingestion"},"content":"\n\n# Now that the item was created we can pass it to eoAPI for ingestion\n\nurl = f\"{STAC_API_URL}/collections/{COLLECTION_ID}/items\"\nresponse = requests.post(url, json=item.to_dict())\n\nif response.status_code in [200, 201]:\n    print(\"Successfully posted STAC Item.\")\nelse:\n    print(f\"Error {response.status_code}: {response.text}\")\n\n\n\n# Update temporal and spatial extent based on ingested datasets\nimport requests\n\ndef update_stac(url, cid):\n    # 1. Fetch all items (limited to 1000 for brevity)\n    items = requests.get(f\"{url}/collections/{cid}/items?limit=1000\").json()['features']\n    \n    # 2. Extract and calculate (flatten coordinates and collect dates)\n    coords = [pt for f in items for pt in f['geometry']['coordinates'][0]]\n    dts = [f['properties']['datetime'] for f in items]\n    \n    # 3. Patch the collection\n    ext = {\n        \"spatial\": {\"bbox\": [[min(c[0] for c in coords), min(c[1] for c in coords), \n                             max(c[0] for c in coords), max(c[1] for c in coords)]]},\n        \"temporal\": {\"interval\": [[min(dts), max(dts)]]}\n    }\n    \n    r = requests.patch(f\"{url}/collections/{cid}\", json={\"extent\": ext})\n    print(\"✅ Updated\" if r.ok else f\"❌ Error: {r.text}\")\n\nupdate_stac(STAC_API_URL, COLLECTION_ID)\n\n\n\nfrom IPython.display import Image, display\n\nurl = f\"{eoapi_endpoint}/collections/demo-collection/items/TCI/preview?assets=data\"\ndisplay(Image(url=url, width=500))\n\n","type":"content","url":"/notebooks/eoapi/eoapi-registration#id-4-ingestion","position":13},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example"},"type":"lvl1","url":"/notebooks/pangeo-dask-notebooks/example-wildfires","position":0},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example"},"content":"","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires","position":1},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Create a burn severity maps using Sentinel-2 Cloud-Optimised Dataset"},"type":"lvl3","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#create-a-burn-severity-maps-using-sentinel-2-cloud-optimised-dataset","position":2},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Create a burn severity maps using Sentinel-2 Cloud-Optimised Dataset"},"content":"","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#create-a-burn-severity-maps-using-sentinel-2-cloud-optimised-dataset","position":3},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Context"},"type":"lvl3","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#context","position":4},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Context"},"content":"","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#context","position":5},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl4":"Purpose","lvl3":"Context"},"type":"lvl4","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#purpose","position":6},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl4":"Purpose","lvl3":"Context"},"content":"Demonstrate how to fetch satellite Sentinel-2 data to generate burn severity maps for the assessment of the areas affected by wildfires.","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#purpose","position":7},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl4":"Methodology approach","lvl3":"Context"},"type":"lvl4","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#methodology-approach","position":8},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl4":"Methodology approach","lvl3":"Context"},"content":"Access Sentinel-2 L2A cloud optimised dataset through STAC\n\nCompute the Normalised Burn Ratio (NBR) index to highlight burned areas\n\nClassify burn severity","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#methodology-approach","position":9},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl4":"Highlights","lvl3":"Context"},"type":"lvl4","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#highlights","position":10},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl4":"Highlights","lvl3":"Context"},"content":"The NBR index uses near-infrared (NIR) and shortwave-infrared (SWIR) wavelengths.","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#highlights","position":11},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl5":"Related publications","lvl4":"Highlights","lvl3":"Context"},"type":"lvl5","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#related-publications","position":12},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl5":"Related publications","lvl4":"Highlights","lvl3":"Context"},"content":"https://​www​.sciencedirect​.com​/science​/article​/pii​/S1470160X22004708​#f0035\n\nhttps://github.com/yobimania/dea-notebooks/blob/e0ca59f437395f7c9becca74badcf8c49da6ee90/Fire Analysis Compiled Scripts (Gadi)/dNBR_full.py\n\n","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#related-publications","position":13},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Dask use ‘Client’ as well, thus pystac_client  is renamed"},"type":"lvl3","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#dask-use-client-as-well-thus-pystac-client-is-renamed","position":14},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Dask use ‘Client’ as well, thus pystac_client  is renamed"},"content":"\n\nimport os\n#import dask.distributed\n\nfrom pystac_client import Client as pystac_client\nfrom odc.stac import configure_rio, stac_load\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\n\n\n","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#dask-use-client-as-well-thus-pystac-client-is-renamed","position":15},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl2":"Get Dask Client"},"type":"lvl2","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#get-dask-client","position":16},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl2":"Get Dask Client"},"content":"\n\nfrom dask_gateway import Gateway\ngateway = Gateway()\n\n\n\ncluster_options = gateway.cluster_options()\ncluster_options\n\n\n\nimport sys\ncluster_options.env_path = sys.prefix\n\n\n\ncluster = gateway.new_cluster(cluster_options=cluster_options)\n# cluster = gateway.new_cluster(cluster_options=cluster_options)\ncluster.scale(2)\nclient = cluster.get_client()\nclient\n\n\n\ncluster = gateway.connect(gateway.list_clusters()[0].name)\n\n# cluster.shutdown()\ngateway.list_clusters()\nclient = cluster.get_client()\nclient\n\n\n\n# import os\n# client.run(os.getenv, 'CONDA_PREFIX')\n\n\n\n\n","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#get-dask-client","position":17},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Set project structure","lvl2":"Get Dask Client"},"type":"lvl3","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#set-project-structure","position":18},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Set project structure","lvl2":"Get Dask Client"},"content":"The cell below creates a separate folder to save the notebook outputs. This facilitates the reader to inspect inputs/outputs stored within a defined destination folder. Change <replace-by-notebook-filename> with your notebook identifier.\n\nnotebook_folder = './wildfires-foss4g'\nif not os.path.exists(notebook_folder):\n    os.makedirs(notebook_folder)\n\n\n\n","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#set-project-structure","position":19},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Load data","lvl2":"Get Dask Client"},"type":"lvl3","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#load-data","position":20},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Load data","lvl2":"Get Dask Client"},"content":"Load full dataset from original or mirror sources. If the license of the dataset permits, we suggest creating sample data (preprocessed) for the notebook stored in a data repository e.g. Zenodo.\n\nindex_name = 'NBR'\n\nbandnames_dict = {\n    'nir': 'nir',\n    'swir22': 'swir22'\n}\n\nkm2deg = 1.0 / 111\nx, y = (23.9983519, 37.7351433)  # Center point of a query\nr = 4 * km2deg  \nbbox = (x - r, y - r, x + r, y + r)\nzoom = 1\n\ncrs = \"epsg:3857\"  # projection on which the data will be projected\n\n# Normalised Burn Ratio, Lopez Garcia 1991\n# index_dict = {'NBR': lambda ds: (ds.nir - ds.swir22) / (ds.nir + ds.swir22)}\n\ndef calc_nbr(ds):\n    return (ds.nir - ds.swir22) / (ds.nir + ds.swir22)\n\nindex_dict = {'NBR': calc_nbr}\nindex_dict\n\n\n\n","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#load-data","position":21},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Show location on a map","lvl2":"Get Dask Client"},"type":"lvl3","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#show-location-on-a-map","position":22},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Show location on a map","lvl2":"Get Dask Client"},"content":"\n\nfig = plt.figure(1, figsize=[15, 10])\n\n# We're using cartopy and are plotting in PlateCarree projection \n# (see documentation on cartopy)\nax = plt.subplot(1, 1, 1, projection=ccrs.PlateCarree())\nax.set_extent([15.5, 27.5, 36, 41], crs=ccrs.PlateCarree()) # lon1 lon2 lat1 lat2\nax.coastlines(resolution='10m')\nax.gridlines(draw_labels=True)\nax.add_feature(cfeature.OCEAN)\nax.add_feature(cfeature.LAND)\n\nplt.plot(x, y,\n         color='magenta', markersize=15, marker='s',\n         transform=ccrs.PlateCarree(),\n         )\n\n# One way to customize your title\nplt.title(\"Map of the area of interest\", fontsize=18)\n\n\n\n\n\n## Open Catalog and get data\n\n## DASK UPDATE***\n    \n# time_range = \"2017-08-17/2022-08-20\"\n\n# catalog = pystac_client.open(\"https://catalog.osc.earthcode.eox.at\")\n# query1 = catalog.search(\n#     datetime=time_range, limit=100,\n#     bbox=bbox,\n# )\n# items = list(query1.get_items())\n# items\n\n\n\n# Open a catalog\ncatalog = pystac_client.open(\"https://earth-search.aws.element84.com/v1\")\n\n\n\n\n","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#show-location-on-a-map","position":23},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Increase computation and try Dask","lvl2":"Get Dask Client"},"type":"lvl3","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#increase-computation-and-try-dask","position":24},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Increase computation and try Dask","lvl2":"Get Dask Client"},"content":"\n\nzoom=1/2\nchunk={\"y\":100}\n\n\n\n","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#increase-computation-and-try-dask","position":25},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Search and get data before the fire","lvl2":"Get Dask Client"},"type":"lvl3","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#search-and-get-data-before-the-fire","position":26},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Search and get data before the fire","lvl2":"Get Dask Client"},"content":"time_range contains the period over which data will be searched;\n\nquery contains additional requirements e.g. get data only when the cloud cover is low (< 0.5)\n\n# prefire data\ntime_range = \"2021-08-10/2021-08-16\"\n\nquery1 = catalog.search(\n    collections=[\"sentinel-2-l2a\"], datetime=time_range, limit=100,\n    bbox=bbox, query={\"eo:cloud_cover\": {\"lt\": 0.5}},\n)\n\nitems = list(query1.get_items())\nprint(f\"Found: {len(items):d} datasets\")\n\nitems_pre = min(items, key=lambda item: item.properties[\"eo:cloud_cover\"])\n\nprefire_ds = stac_load(\n    [items_pre],\n    bands=(\"nir\", \"swir22\"),\n    crs=crs,\n    resolution=  10*zoom,\n    chunks=chunk,  # <-- use Dask\n    groupby=\"datetime\",\n    bbox=bbox,\n)\nprefire_ds\n\n\n\n\n\n","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#search-and-get-data-before-the-fire","position":27},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Search and get data after the fire","lvl2":"Get Dask Client"},"type":"lvl3","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#search-and-get-data-after-the-fire","position":28},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Search and get data after the fire","lvl2":"Get Dask Client"},"content":"\n\n##postfire\ntime_range = \"2021-08-17/2021-08-20\"\n\nquery2 = catalog.search(\n    collections=[\"sentinel-2-l2a\"], datetime=time_range, limit=100,\n    bbox=bbox, query={\"eo:cloud_cover\": {\"lt\": 0.5}},\n)\n\nitems = list(query2.get_items())\nprint(f\"Found: {len(items):d} datasets\")\n\nitems_post = min(items, key=lambda item: item.properties[\"eo:cloud_cover\"])\n\npostfire_ds = stac_load(\n    [items_post],\n    bands=(\"nir\", \"swir22\"),\n    crs=crs,\n    resolution=10 * zoom,\n    chunks=chunk,  # <-- use Dask\n    groupby=\"datetime\",\n    bbox=bbox,\n)\npostfire_ds\n\n\n\n\n\n","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#search-and-get-data-after-the-fire","position":29},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Methodology","lvl2":"Get Dask Client"},"type":"lvl3","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#methodology","position":30},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Methodology","lvl2":"Get Dask Client"},"content":"Add code demonstrating the methodology.\n\n# Rename bands in dataset to use simple names \nbands_to_rename = {\n    a: b for a, b in bandnames_dict.items() if a in prefire_ds.variables\n}\n\n# prefire\nprefire_ds[index_name] = index_dict[index_name](prefire_ds.rename(bands_to_rename) / 10000.0)\n\n# postfire\npostfire_ds[index_name] = index_dict[index_name](postfire_ds.rename(bands_to_rename) / 10000.0)\n\n\n\n\n# calculate delta NBR\nprefire_burnratio = prefire_ds.NBR.isel(time=0)\npostfire_burnratio = postfire_ds.NBR.isel(time=0)\n\ndelta_NBR = prefire_burnratio - postfire_burnratio\n\ndnbr_dataset = delta_NBR.to_dataset(name='delta_NBR')\n\n\n\n","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#methodology","position":31},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Outputs","lvl2":"Get Dask Client"},"type":"lvl3","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#outputs","position":32},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Outputs","lvl2":"Get Dask Client"},"content":"Provide a brief inspection of the methodology outputs and their interpretation\n\ndnbr_dataset\ndelta_NBR\n\n\n\n","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#outputs","position":33},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Zoom on the area","lvl2":"Get Dask Client"},"type":"lvl3","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#zoom-on-the-area","position":34},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Zoom on the area","lvl2":"Get Dask Client"},"content":"DASK ‘lazy’ computation starts here.  Watchout the Task Stream and Worker CPU usage for following 3 plots!!\n\nfig = plt.figure(1, figsize=[7, 10])\n\n# We're using cartopy and are plotting in PlateCarree projection \n# (see documentation on cartopy)\nax = plt.subplot(1, 1, 1, projection=ccrs.PlateCarree())\n#ax.set_extent([-180, 180, -70, 70], crs=ccrs.PlateCarree()) # lon1 lon2 lat1 lat2\nax.coastlines(resolution='10m')\nax.gridlines(draw_labels=True)\n\n# We need to project our data to the new Orthographic projection and for this we use `transform`.\n# we set the original data projection in transform (here Mercator)\nprefire_burnratio.plot(ax=ax, transform=ccrs.epsg(prefire_burnratio.spatial_ref.values), cmap='RdBu_r',\n                       cbar_kwargs={'orientation':'horizontal','shrink':0.95})\n\n# One way to customize your title\nplt.title( pd.to_datetime(prefire_burnratio.time.values.item()).strftime(\"%d %B %Y\"), fontsize=18)\n\n\n\nfig = plt.figure(1, figsize=[7, 9])\n\n# We're using cartopy and are plotting in PlateCarree projection \n# (see documentation on cartopy)\nax = plt.subplot(1, 1, 1, projection=ccrs.PlateCarree())\n#ax.set_extent([-180, 180, -70, 70], crs=ccrs.PlateCarree()) # lon1 lon2 lat1 lat2\nax.coastlines(resolution='10m')\nax.gridlines(draw_labels=True)\n\n# We need to project our data to the new Orthographic projection and for this we use `transform`.\n# we set the original data projection in transform (here Mercator)\npostfire_burnratio.plot(ax=ax, transform=ccrs.epsg(postfire_burnratio.spatial_ref.values), cmap='RdBu_r',\n                        cbar_kwargs={'orientation':'horizontal','shrink':0.95})\n\n# One way to customize your title\nplt.title( pd.to_datetime(postfire_burnratio.time.values.item()).strftime(\"%d %B %Y\"), fontsize=18)\n\n\n\nfig = plt.figure(1, figsize=[7, 10])\n\n# We're using cartopy and are plotting in PlateCarree projection \n# (see documentation on cartopy)\nax = plt.subplot(1, 1, 1, projection=ccrs.PlateCarree())\nax.coastlines(resolution='10m')\nax.gridlines(draw_labels=True)\n\n# We need to project our data to the new Orthographic projection and for this we use `transform`.\n# we set the original data projection in transform (here Mercator)\ndnbr_dataset.delta_NBR.plot(ax=ax, transform=ccrs.epsg(dnbr_dataset.delta_NBR.spatial_ref.values), cmap='RdBu_r',\n                            cbar_kwargs={'orientation':'horizontal','shrink':0.95})\n\n# One way to customize your title\nplt.title( \"Delta NBR\", fontsize=18)\n\n\n\n","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#zoom-on-the-area","position":35},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Save Dataset as .zarr","lvl2":"Get Dask Client"},"type":"lvl3","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#save-dataset-as-zarr","position":36},{"hierarchy":{"lvl1":"Scale your processes with Dask - hands on example","lvl3":"Save Dataset as .zarr","lvl2":"Get Dask Client"},"content":"\n\n# Define the output path within your notebook folder\noutput_path = os.path.join(notebook_folder, \"dnbr_dataset.zarr\")\n\n# Because your dataset is lazy (using Dask), it may not have computed all values before the write is attempted. Try computing the dataset explicitly before saving:\n# This ensures that all lazy operations are materialized in memory, which can sometimes resolve issues with missing metadata.\ndnbr_dataset = dnbr_dataset.compute()\n\n# save\ndnbr_dataset.to_zarr(output_path, mode=\"w\")\n\n\n\n\n\n\n# import os\n# import xarray as xr\n\n# # Define the folder where your Zarr store is saved\n# notebook_folder = './wildfires-foss4g'\n# zarr_path = os.path.join(notebook_folder, \"dnbr_dataset.zarr\")\n\n# # Use the same chunking scheme as before\n# chunk = {\"y\": 100}\n\n# # Open the Zarr store as a Dask-backed xarray.Dataset\n# dnbr_ds = xr.open_zarr(zarr_path, chunks=chunk)\n\n# dnbr_ds\n\n","type":"content","url":"/notebooks/pangeo-dask-notebooks/example-wildfires#save-dataset-as-zarr","position":37}]}